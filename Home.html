<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <link rel="stylesheet" href="Style.css">
    <title>Home</title>
  </head>
  <body>
    <div class="dropdown">
      <div class="navDrop">Navigation▼</div>
      <div class="navLinks" id="navigation">
        <ul><a class="primary" href="Home.html">Home</a></ul>
        <ul><a class="primary" href="Matching.html">Matching game</a></ul>
        <ul><a class="primary" href="Index.html">Converter</a></ul>
        <a class="secondary" href="Home.html">Home</a>
        <a class="secondary" href="Matching.html">Matching game</a>
        <a class="secondary" href="Index.html">Converter</a>
      </div>
    </div>
    <p>Data representation is the different ways that information can be conveyed. In computing
a binary representation is used due to the manner it can be processed and stored.
Binary is a base 2 representation and conveys a value of 1 or 0 with methods dependent
on the disk type. Many disks and hardware that represents will store the value with
different voltage states, others can represent it with the magnetic state of the
components. Every binary number processed in computing is called a bit. Bits are used
to represent all the information stored including colour and text, the amount it can store
depends on how these bits are processed. Working as a base-2 number system every
new bit in a string increases the possible representations by a power of 2. This allows for
a larger number representation when string increase in size. Every bit is twice the bit to
its right starting with 1 at the last spot. When a digit is one it will add the number
represented by its space to the total and will continue adding to the last digit. This is how
binary is converted to decimal numbers. For example the binary string 010011 will
create (0*32)+(1*16)+(0*8)+(0*4)+(1*2)+(1*1) which is the decimal number 19. Working
with decimal numbers and converting them to binary requires subtracting the number by
the placement representation, if it is negative the value of that place is 0 and the
subtraction is ignored, if it is positive the value is one and the subtraction is continued to
the next placement. E.g. 29, 32-29=-3 value of 0, 29-16=13 value of 1, 13-8=5 value of
1, 5-4=1 value of 1, 1-2=-1 value of 0, 1-1=0 value of 1, final representation 011101.
When working with information the number of bits quickly becomes too large to talk
about easily, due to this, other words are used when referencing higher numbers of bits.
A byte is made up of 8 bits, a kilobyte is 8192 bits or 1024 bytes, and a megabyte is
8388608 bits or 1024 kilobytes. This continues in this fashion following the standard
metric unit prefix system.
Representing Colour
In computing, colours are typically represented in with a red, green, and blue values.
This is due to the fact that the human eye perceives colours through respective cones.
By changing the amount of each colour different colours and shades can be created and
used to create an image. The value for each colour is represented by bits. The more bits
there are, the more accurate the colour is represented. Typical hexadecimal colours are
represented by 24 bits, or 8 bits for each primary colour.

1

0374
NSN: 125491967
AS91371
The representation of this turquoise using 24-bits is in binary will be divided into 3
8-bit segments and displayed as 001010001101110110101100. As decimal values
for red, green, and blue these are r40,g221,b172. Another common way to
represent this is with hexadecimal numbers as it makes it easier to understand.
Hexadecimal numbers are found using 4 bits aka a nibble, they range from 0-9 and a-f.
The example colour has 0010 as its first nibble and makes the hexadecimal value of 2
and 1000 becomes 8 this is the red byte. The green and blue bytes both become letters
in hexadecimal as the nibbles are all over 9, for green both nibbles of 1101 become d as
they are 5 numbers over 9, blues nibbles of 1010 and 1100 become a and c respectively
due to the amount they are over 9. After finding these values the hexadecimal value for
the colour is 28ddac.
To reduce the size of an image it is possible to change the colour depth. Changing the
depth refers to changing the number of bits used to represent each colour. Websites
often use colours that can be formed using fewer bits as browsers didn’t always have
the ability to represent more than 256 colours at the same time. When the colour depth
of an image gets reduces there tends to be a greater impact on how it looks than there
is in the size difference.

24-bit 8-bit

The reduction of colour depth for the colour 28ddac to an 8-bit
representation will require the binary pattern to be reduced for each
colour to the number of bits used, e.g. red 00101000→001, green
11011101→110, blue 10101100→10. 8-bit colour 00111010. The
difference between these colour depths is minimal with this colour but
with a colour like the purple, there is a larger difference.
With 8 bits a maximum of 256 colours can be displayed (28

) whereas with 24 bits

16777216 different colours can be displayed (224

). This is the cause of the difference in
shade between the different colour depth as the colours 8-bit colours have a less
precise representation of colours due to its lack of bits compared to 24-bit.

2

0374
NSN: 125491967
AS91371

24-Bit 8-Bit

Colours which rely on a smooth gradient suffer greatly from bit reduction. The number of
bits dedicated to blue is reduced to 2 while the others are at 3 causing a greater
difference when there is a larger concentration of blue as seen with the sky above.
Objects with small bits of different colour spread throughout are made to look worse as
seen on the launch-pad and the mountains in the background, shadows are blocked
together and gives a more blocky appearance to the shaders used. This example is
largely reduced in quality for a small saving in space and would not be worth
compressing in this way.
32-bit colour is also used frequently as 8 bits are put towards the alpha channel which
causes transparency. More bits could also be required when the contrast is changed.
This is due to the change in light level making colours lighter or darker at different rates.
The use of fewer bits is often done when a small amount of space needs to be saved.
The quality is often impacted more than would be beneficial in space saved. The
benefits for size saved are when images need to be loaded when there is a limited
internet connection or when there is a greater need for faster image transfer.

Representing Text
When computers were first developed different techniques were used to portray
information from binary. As there are multiple languages different regions used different
representations for different letters or characters. This caused difficulty when trying to
transfer data from one computer system to another. To prevent multiple different
representations for english information, America created ASCII, American Standard
Code for Information Interchange. ASCII uses the numbers generated from an 8-bit
sequence of binary to determine what character is being represented. Running on an
8-bit system ASCII uses 128 different options. To represent this there is only a
requirement of 7 bits, but, due to ease of workability, one bit is wasted to bring the total
3

0374
NSN: 125491967
AS91371
up to a byte. The first 32 characters in an ASCII table are known as ‘control’ characters,
they are used to interface with the computer without adding any text. The last character
is also a control character. Numbers begin at 48 with 0 as in binary this is represented
by 00110000, the pattern it is based off is after removing the first 4 numbers the
remaining will be the representation for the original number. ASCII for 1 is 49 which in
binary is 00110001 with 1 in binary being 0001. Letters work in a similar way as, starting
with the capitals, A being 65 is represented in binary as 01000001. Removing the first 2
digits it starts at one and continues up for each number. Lowercase letters start 32
numbers latter for the same reason with a being 01100001 and continuing up for each
letter. Other expressions are placed nearby to each other for the remaining characters.
For the time when computers worked together within America this worked well, the
problems were still there but they were heavily reduced. The next change in
standardised languages came when international communication became more popular
and the World Wide Web. Unicode is a character set containing different languages
characters to enable information transfer without corruption.
Unicode can be represented in many ways, the most common are UTF-8, UTF-16 and
UTF-32 using a minimum number of bits of 8, 16 and 32 respectively. Depending on the
type of data that you want to represent will determine which UTF will be used, UTF-8 is
best for English characters, UTF-16 is best for Asian characters while UTF-32 will use
the same amount of space than both of the others. UTF-32 is a fixed length encoding
scheme and, as such, will always use the same number of bits for representing any
character, English or otherwise, of 32 bits. This is the main reason it is the least used
encoding system of the three. UTF-8 and UTF-16 are both variable length encoding
schemes. This means that they will change the number of bits they use depending on
how many are required. Every character in UTF-8 is represented in any of 8, 16, 24 or
32 bits depending on their Unicode number. Within each byte only 7 are used to
represent the number similar to ASCII, the 8th bit is, instead of being wasted, used to
represent a continuation. This allows for the expansion of representations allowed. In a
16-bit representation of UTF-8, the first byte will start with a 0 to show that it is the first
byte of a sequence, the second bit will start with a 1 to represent the fact that it is the
continuation of the second. This leaves 14 bits to represent the number of the character
in Unicode. This is also the reason that UTF-16 is more efficient at representing Asian
characters, UTF-16 has the capability to use more of the 15 of its bits increasing the
representable characters by an additional power of 2. The basis for the characters in
Unicode is the same in the ASCII character set (‘a’ being 97 for both and ‘!’ is 33). This
is the reason UTF-8 is the most efficient with English characters than others as it only
requires the same bits as ASCII did. UTF-16 is inefficient for English characters as it will
use 16 bits rather than the 8 required in UTF-8, it is, however, better at representing
Asian text as shown with this Japanese sentence, ‘今日、私はジャガイモを食べた.’
4

0374
NSN: 125491967
AS91371
Representing this in UTF-8 will require the use of 312 bits while in UTF-16 it only
requires 208 bits UTF-32 requires 448 bits. The same sentence in English, ‘Today, I ate
a potato’ requires 168 bits in UTF-8 and 336 bits in UTF-16, UTF-32 uses 672 bit.
</p>
    <script src="Index.js" charset="utf-8"></script>
  </body>
</html>
